{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Constraint/Column Generation and the Cutting Stock Problem\n",
    "\n",
    "In this Jupyter Notebook, we will be exploring the cutting stock problem using Python and Gurobi. We will begin by solving the problem by simply enumerating patterns. We will then see three different approaches: (exact) constraint generation, heuristic constraint generation, and constraint randomization/sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cutting stock problem with two patterns\n",
    "\n",
    "In our initial formulation of this problem, we are told that we have 3 types of demand: 3 inch rolls; 5 inch rolls; 7 inch rolls. We need to meet demand for these 3 types by cutting large rolls of 20 inches according to _patterns_.\n",
    "\n",
    "We are told that we will only consider two types of patterns:\n",
    "- Pattern 1: [3, 2, 0] (3 x 3 inch rolls; 2 x 5 inch rolls; 0 x 7 inch rolls)\n",
    "- Pattern 2: [2, 1, 1] (2 x 3 inch rolls; 1 x 5 inch rolls; 1 x 7 inch rolls)\n",
    "\n",
    "We are told that we need:\n",
    "- 22 rolls of type 1 (3 inches)\n",
    "- 10 rolls of type 2 (5 inches)\n",
    "- 5 rolls of type 3 (7 inches)\n",
    "\n",
    "We can formulate the problem as the following linear program. Let $x_1$ be the number of large rolls we cut according to pattern 1, and similarly let $x_2$ be the number of large rolls cut according to pattern 2. With the goal of minimizing the total number of large rolls that we use, we can write the problem down as the following linear program:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\text{minimize} & & x_1 + x_2 \\\\\n",
    "& \\text{subject to} & & 3 x_1 + 2 x_1 \\geq 22, \\\\\n",
    "& & & 2 x_1 + x_2 \\geq 10, \\\\\n",
    "& & & x_2 \\geq 5, \\\\\n",
    "& & & x_1, x_2 \\geq 0.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that the above formulation allows for the number of patterns to be cut to be fractional. As we have seen in some of our LP formulations earlier, we will not worry about this. \n",
    "\n",
    "Let's now formulate this in Python/Gurobi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2025-11-24\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (mac64[arm] - Darwin 23.2.0 23C71)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 3 rows, 2 columns and 5 nonzeros\n",
      "Model fingerprint: 0x88576948\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+00, 2e+01]\n",
      "Presolve removed 1 rows and 0 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 2 rows, 2 columns, 4 nonzeros\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    9.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "       0    9.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  9.000000000e+00\n",
      "Optimal solution:  [4.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "from gurobipy import *\n",
    "import numpy as np\n",
    "\n",
    "nDemands = 3\n",
    "d = np.array([22, 10, 5])\n",
    "\n",
    "nPatterns = 2\n",
    "patterns = [ [3,2,0], [2,1,1]]\n",
    "\n",
    "m = Model()\n",
    "x = m.addVars(nPatterns)\n",
    "\n",
    "for i in range(nDemands):\n",
    "    m.addConstr(sum( patterns[j][i] * x[j] for j in range(nPatterns) ) >= d[i])\n",
    "    \n",
    "m.setObjective( sum(x[j] for j in range(nPatterns)), GRB.MINIMIZE)\n",
    "\n",
    "m.update()\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "x_vals = [ x[j].x for j in range(nPatterns)]\n",
    "\n",
    "print(\"Optimal solution: \", x_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our optimal solution is to cut 4 rolls according to pattern 1, and 5 rolls according to pattern 2. (Note that although we were lucky here and the optimal values came out as integers, this will not be the case in general. As an example, if you change `d[0]` to 20, you will get a fractional number of rolls for the first pattern.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cutting stock problem with a large number of patterns (exhaustive enumeration)\n",
    "\n",
    "In the previous example, the two patterns were chosen arbitrarily. In reality, we are free to cut the large rolls according to any pattern we like.\n",
    "\n",
    "So now, suppose that we enumerate all of the possible patterns. Mathematically, this would mean that we have $n$ patterns, where each pattern $j \\in \\{1,\\dots,n\\}$ is a vector $\\mathbf{a}_j = (a_{1,j}, a_{2,j}, \\dots, a_{m,j})$ that tells us how many rolls of each demand type will be cut from the large rolls. \n",
    "\n",
    "The LP can then be written as \n",
    "$$\n",
    "\\begin{alignat}{2}\n",
    "& \\text{minimize} & \\quad & \\sum_{j=1}^n x_j \\\\\n",
    "& \\text{subject to} & & \\sum_{j=1}^n a_{1,j} x_j \\geq d_1, \\\\\n",
    "& & & \\sum_{j=1}^n a_{2,j} x_j \\geq d_2, \\\\\n",
    "& & & \\vdots \\\\\n",
    "& & & \\sum_{j=1}^n a_{m,j} x_j \\geq d_m, \\\\\n",
    "& & & x_1, \\dots, x_n \\geq 0.\n",
    "\\end{alignat}\n",
    "$$\n",
    "\n",
    "Let's now see how we can enumerate all of the patterns in Python and then formulate the LP using Gurobi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the widths of the large roll and the small rolls:\n",
    "W = 20 # width of a large roll \n",
    "w = [3, 5, 7] # widths of the three different small rolls\n",
    "\n",
    "# In Python, // will perform integer / \"floor\" division (do an ordinary division, \n",
    "# and then take the floor() of the result)\n",
    "print(\"W // w[0]: \", W // w[0])\n",
    "\n",
    "a_ranges = [ list(range( W // w[i] + 1 ) ) for i in range(nDemands)]\n",
    "print(a_ranges)\n",
    "\n",
    "# To obtain the patterns, let's use a simple list comprehension with a condition:\n",
    "patterns = [ (i,j,k) for i in a_ranges[0] for j in a_ranges[1] for k in a_ranges[2] if w[0]*i+w[1]*j+w[2]*k<=W]\n",
    "\n",
    "# Count the number of patterns:\n",
    "nPatterns = len(patterns)\n",
    "print(\"nPatterns = \", nPatterns)\n",
    "\n",
    "# Notice that this is much smaller than the theoretical upper bound of 105!\n",
    "\n",
    "# Let's proceed with formulating the problem:\n",
    "\n",
    "m = Model()\n",
    "x = m.addVars(nPatterns)\n",
    "\n",
    "for i in range(nDemands):\n",
    "    m.addConstr( sum( patterns[j][i] * x[j] for j in range(nPatterns) ) >= d[i])\n",
    "    \n",
    "m.setObjective( sum(x[j] for j in range(nPatterns)), GRB.MINIMIZE)\n",
    "\n",
    "m.update()\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "x_vals = [ x[j].x for j in range(nPatterns)]\n",
    "print()\n",
    "print(\"Optimal solution: \", x_vals)\n",
    "print()\n",
    "nonzero_pattern_indices = [j for j in range(nPatterns) if x_vals[j] > 0]\n",
    "\n",
    "for j in nonzero_pattern_indices:\n",
    "    print(\"Pattern \", j, \": \", patterns[j], \" -- cut \", x_vals[j], \" rolls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual of the cutting stock problem\n",
    "\n",
    "Of course, we can also solve this same problem using the dual:\n",
    "\n",
    "$$\n",
    "\\begin{alignat}{2}\n",
    "& \\text{maximize} & & \\sum_{i=1}^m d_i p_i \\\\\n",
    "& \\text{subject to} & \\quad & \\sum_{i=1}^m a_{i,1} p_i \\leq 1, \\\\\n",
    "& & & \\sum_{i=1}^m a_{i,2} p_i \\leq 1, \\\\\n",
    "& & & \\vdots \\\\\n",
    "& & & \\sum_{i=1}^m a_{i,n} p_i \\leq 1, \\\\\n",
    "& & & p_1,\\dots, p_m \\geq 0. \n",
    "\\end{alignat}\n",
    "$$\n",
    "\n",
    "Let's formulate this problem in Gurobi below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dual = Model()\n",
    "p = m_dual.addVars(nDemands)\n",
    "\n",
    "for j in range(nPatterns):\n",
    "    m_dual.addConstr( sum( patterns[j][i] * p[i] for i in range(nDemands) ) <= 1)\n",
    "    \n",
    "m_dual.setObjective( sum( d[i] * p[i]  for i in range(nDemands)), GRB.MAXIMIZE)\n",
    "\n",
    "m_dual.update()\n",
    "\n",
    "m_dual.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the cutting stock problem using constraint generation\n",
    "\n",
    "In the previous example, we only had a small number of demand types and the number of possible patterns was small enough that we could enumerate it completely, and solve the problem. In general, this will not be feasible when we have a large number of demand types, and there is an enormous number of patterns to consider.\n",
    "\n",
    "In what follows below, we are going to implement a constraint generation approach for solving this problem. The idea is that we are going to solve the dual, check for violated constraints, and then add them as needed.\n",
    "\n",
    "To begin, let us set the width and demand parameters to the ones of our larger example from the slides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 200\n",
    "w = [3,5,7,10,17,22,30,50]\n",
    "nDemands = 8\n",
    "# d = np.ones(nDemands) * 2000 \n",
    "d = [1200,1000,1000,400,500,400,600,200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to formulate the separation problem. Recall that the separation problem is the problem that we solve to determine if there is a violated constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"sub\" indicates that this is the subproblem in our CG method.\n",
    "m_sub = Model() \n",
    "\n",
    "a = m_sub.addVars(nDemands, vtype = GRB.INTEGER)\n",
    "p_val = np.ones(nDemands)\n",
    "\n",
    "m_sub.addConstr( sum(w[i] * a[i] for i in range(nDemands)) <= W)\n",
    "m_sub.setObjective( sum(p_val[i] * a[i] for i in range(nDemands)), GRB.MAXIMIZE)\n",
    "\n",
    "m_sub.update()\n",
    "\n",
    "# Test it out:\n",
    "m_sub.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The subproblem is working. Let's actually create a function now, to help us solve it repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation(p_val):\n",
    "    m_sub.setObjective( sum(p_val[i] * a[i] for i in range(nDemands)), GRB.MAXIMIZE)\n",
    "    m_sub.update()\n",
    "    m_sub.optimize()\n",
    "    \n",
    "    a_val = [a[i].x for i in range(nDemands)]\n",
    "    sub_obj = m_sub.objval\n",
    "    \n",
    "    return sub_obj, a_val\n",
    "\n",
    "# Test it out (set OutputFlag to zero, to not flood notebook with output:)\n",
    "m_sub.Params.OutputFlag = 0\n",
    "\n",
    "sub_obj, a_val = separation( [2, 3, 5, 0, 0, 0, 0, 0] )\n",
    "print(sub_obj, a_val)\n",
    "\n",
    "sub_obj, a_val = separation( [2, 2, 2, 1, 5, 1, 1, 1] )\n",
    "print(sub_obj, a_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our constraint generation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformulate the dual problem. \n",
    "m_dual = Model()\n",
    "\n",
    "m_dual.Params.OutputFlag = 0\n",
    "\n",
    "p = m_dual.addVars(nDemands)\n",
    "\n",
    "m_dual.setObjective(sum(d[i] * p[i] for i in range(nDemands)), GRB.MAXIMIZE)\n",
    "\n",
    "# Let us initialize the set of patterns with just those that consist only of a single demand type.\n",
    "# We can enumerate that set as follows:\n",
    "\n",
    "patterns = [ [1 for i in range(nDemands)] ]\n",
    "print(patterns)\n",
    "\n",
    "nPatterns = len(patterns)\n",
    "\n",
    "for j in range(nPatterns):\n",
    "    m_dual.addConstr( sum( patterns[j][i] * p[i] for i in range(nDemands)) <= 1)\n",
    "    \n",
    "m_dual.update()\n",
    "m_dual.optimize()\n",
    "\n",
    "\n",
    "\n",
    "dual_obj = m_dual.objval\n",
    "\n",
    "CG_iter = 0\n",
    "\n",
    "print(\"Iteration \", CG_iter, \": \", dual_obj)\n",
    "\n",
    "\n",
    "p_val = [p[i].x for i in range(nDemands)]\n",
    "\n",
    "print(p_val)\n",
    "\n",
    "\n",
    "\n",
    "sub_objval, a_val = separation(p_val)\n",
    "\n",
    "tol_eps = 1e-5\n",
    "\n",
    "isOptimal = sub_objval <= 1 + tol_eps # Why do we do this?\n",
    "\n",
    "while (not isOptimal):\n",
    "    # Add a_val to patterns, and add the constraint to the dual.\n",
    "    patterns.append(a_val)\n",
    "    m_dual.addConstr( sum( a_val[i] * p[i] for i in range(nDemands)) <= 1)\n",
    "    \n",
    "    # Update the problem and solve it again.\n",
    "    m_dual.update()\n",
    "    m_dual.optimize()\n",
    "    dual_obj = m_dual.objval\n",
    "    p_val = [p[i].x for i in range(nDemands)]\n",
    "    \n",
    "    CG_iter += 1 \n",
    "    print()\n",
    "    print(\"Iteration \", CG_iter, \": \", dual_obj)\n",
    "    \n",
    "    # Solve separation problem, and update the isOptimal flag.\n",
    "    sub_objval, a_val = separation(p_val)\n",
    "    isOptimal = sub_objval <= 1 + tol_eps\n",
    "    print(\"sub_objval = \", sub_objval)\n",
    "    print(\"constraint violation = \", 1 - sub_objval),\n",
    "    print(\"a_val = \", a_val)\n",
    "    print(\"isOptimal = \", isOptimal)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out the solution to the original problem, let's formulate the primal and solve again (the cell below is just reusing some code from earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPatterns = len(patterns)\n",
    "\n",
    "m = Model()\n",
    "x = m.addVars(nPatterns)\n",
    "\n",
    "for i in range(nDemands):\n",
    "    m.addConstr( sum( patterns[j][i] * x[j] for j in range(nPatterns) ) >= d[i])\n",
    "    \n",
    "m.setObjective( sum(x[j] for j in range(nPatterns)), GRB.MINIMIZE)\n",
    "\n",
    "m.update()\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "x_vals = [ x[j].x for j in range(nPatterns)]\n",
    "\n",
    "print(\"Optimal solution: \", x_vals)\n",
    "\n",
    "nonzero_pattern_indices = [j for j in range(nPatterns) if x_vals[j] > 0]\n",
    "\n",
    "for j in nonzero_pattern_indices:\n",
    "    print(\"Pattern \", j, \": \", patterns[j], \" -- cut \", x_vals[j], \" rolls\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic constraint generation\n",
    "Instead of solving the separation problem as an integer program, we can also consider solving it using a heuristic. Consider the following heuristic:\n",
    "1. Given the $p_i$ values, calculate a index $r_i = p_i / w_i$. \n",
    "2. Sort the demand types from largest to smallest value of the index $r_i$, so that $r_{(1)} \\geq r_{(2)} \\geq \\dots \\geq r_{(m)}$. \n",
    "3. For $i = 1,\\dots,m$, set \n",
    "$a_{(i)} =  \\left \\lfloor \\frac{W - \\sum_{i'=1}^{i-1} a_{(i')} w_{(i')}}{w_{(i)}} \\right\\rfloor $.\n",
    "\n",
    "This type of heuristic is known as a \"bang-for-buck\" heuristic. The index $r_i$ tells us what is the \"bang-for-buck\" of each demand type (how much it adds to the separation problem objective per inch it uses of the large roll). The heuristic then builds the pattern in order of this index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation_heuristic(p_val):\n",
    "    r = [ p_val[i] / w[i] for i in range(nDemands) ]\n",
    "    order = np.argsort( r )\n",
    "    order = np.flip(order)\n",
    "    \n",
    "    a_val = np.zeros(nDemands)\n",
    "    remaining_width = W\n",
    "    for i in order:\n",
    "        a_val[i] = remaining_width // w[i]\n",
    "        remaining_width -= a_val[i] * w[i]\n",
    "        \n",
    "    sub_objval = sum( [ a_val[i] * p_val[i] for i in range(nDemands) ])\n",
    "    \n",
    "    return sub_objval, a_val\n",
    "\n",
    "\n",
    "p_val = [0.05, 0.01, 0.03, 0.02]\n",
    "print( np.argsort(p_val))\n",
    "\n",
    "\n",
    "m_dual = Model()\n",
    "\n",
    "m_dual.Params.OutputFlag = 0\n",
    "\n",
    "p = m_dual.addVars(nDemands)\n",
    "\n",
    "m_dual.setObjective(sum(d[i] * p[i] for i in range(nDemands)), GRB.MAXIMIZE)\n",
    "\n",
    "# Let us initialize the set of patterns with just those that consist only of a single demand type.\n",
    "# We can enumerate that set as follows:\n",
    "\n",
    "patterns = [ [1 for i in range(nDemands)] ]\n",
    "print(patterns)\n",
    "\n",
    "nPatterns = len(patterns)\n",
    "\n",
    "for j in range(nPatterns):\n",
    "    m_dual.addConstr( sum( patterns[j][i] * p[i] for i in range(nDemands)) <= 1)\n",
    "    \n",
    "m_dual.update()\n",
    "m_dual.optimize()\n",
    "\n",
    "\n",
    "\n",
    "dual_obj = m_dual.objval\n",
    "\n",
    "CG_iter = 0\n",
    "\n",
    "print(\"Iteration \", CG_iter, \": \", dual_obj)\n",
    "\n",
    "\n",
    "p_val = [p[i].x for i in range(nDemands)]\n",
    "\n",
    "sub_objval, a_val = separation_heuristic(p_val)\n",
    "\n",
    "tol_eps = 1e-5\n",
    "\n",
    "isOptimal = sub_objval <= 1 + tol_eps\n",
    "\n",
    "while (not isOptimal):\n",
    "    # Add a_val to patterns, and add the constraint to the dual.\n",
    "    patterns.append(a_val)\n",
    "    m_dual.addConstr( sum( a_val[i] * p[i] for i in range(nDemands)) <= 1)\n",
    "    \n",
    "    # Update the problem and solve it again.\n",
    "    m_dual.update()\n",
    "    m_dual.optimize()\n",
    "    dual_obj = m_dual.objval\n",
    "    p_val = [p[i].x for i in range(nDemands)]\n",
    "    \n",
    "    CG_iter += 1 \n",
    "    print()\n",
    "    print(\"Iteration \", CG_iter, \": \", dual_obj)\n",
    "    \n",
    "    # Solve separation problem, and update the isOptimal flag.\n",
    "    sub_objval, a_val = separation_heuristic(p_val)\n",
    "    isOptimal = sub_objval <= 1 + tol_eps\n",
    "    print(\"sub_objval = \", sub_objval)\n",
    "    print(\"constraint violation = \", 1 - sub_objval),\n",
    "    print(\"a_val = \", a_val)\n",
    "    print(\"isOptimal = \", isOptimal)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_objval, a_val = separation(p_val)\n",
    "print(sub_objval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this heuristic-based constraint generation method terminates prematurely; in the final iteration, the objective value is 326.41, but we know that the optimal is actually 324.5. \n",
    "\n",
    "For many problems, this type of heuristic constraint generation approach will work well -- it will get us the optimal or a near optimal solution, and it can be potentially much faster than when we solve the separation problem as an IP. We can also consider a hybrid scheme, where we first run the heuristic: if the heuristic finds a violated constraint, we add it and solve again; otherwise, if the heuristic indicates that no constraints are violated, we trigger a solve of the integer program to confirm that this is truly the case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization approach\n",
    "\n",
    "This last example is to illustrate a very different approach to solving large scale LPs, which is based on randomly sampling columns. This is actually a topic of some of my recent research:\n",
    "\n",
    "> Chen, Y.-C. and Misic, V. V. (2020) Column-Randomized Linear Programs: Performance Guarantees and Applications. _Working paper; available online at https://arxiv.org/abs/2007.10461._\n",
    "\n",
    "The idea here is quite simple: rather than adding constraints one at a time, let's _randomly sample_ a collection of constraints, and solve the problem. \n",
    "\n",
    "The function below will randomly sample a pattern. The procedure starts with an empty pattern, and then randomly selects one of the demand types to add to the pattern. It keeps repeating this until it runs out of space on the large roll to add any more demand types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "min_w = min(w)\n",
    "\n",
    "def random_a():\n",
    "    a_val = np.zeros(nDemands)\n",
    "    remaining_width = W\n",
    "    valid_widths = [i for i in range(nDemands) if w[i] <= remaining_width]\n",
    "    while (len(valid_widths) > 0):\n",
    "        i_random = np.random.choice(valid_widths, 1)\n",
    "        i_random = i_random[0]\n",
    "        a_val[i_random] += 1\n",
    "        remaining_width -= w[i_random]\n",
    "        valid_widths = [i for i in range(nDemands) if w[i] <= remaining_width]\n",
    "        \n",
    "    return a_val\n",
    "\n",
    "# Test it out:\n",
    "print(random_a())\n",
    "print(random_a())\n",
    "print(random_a())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's now implement the randomization procedure:\n",
    "\n",
    "np.random.seed(100) #100\n",
    "\n",
    "# Sample 100 random patterns:\n",
    "nPatterns = 100\n",
    "patterns = []\n",
    "for j in range(nPatterns):\n",
    "    patterns.append( random_a() )\n",
    "    \n",
    "# Formulate the dual as per usual:  \n",
    "m_dual = Model()\n",
    "\n",
    "# m_dual.Params.OutputFlag = 0\n",
    "\n",
    "p = m_dual.addVars(nDemands)\n",
    "\n",
    "m_dual.setObjective(sum(d[i] * p[i] for i in range(nDemands)), GRB.MAXIMIZE)\n",
    "\n",
    "for j in range(nPatterns):\n",
    "    m_dual.addConstr( sum( patterns[j][i] * p[i] for i in range(nDemands)) <= 1)\n",
    "    \n",
    "m_dual.update()\n",
    "m_dual.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat surprisingly, this randomized method gets us a solution that is quite close to optimal (325.16, compared to 324.5). Let us see what the actual patterns/allocations look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Solve the primal problem to see which patterns are involved:\n",
    "m = Model()\n",
    "x = m.addVars(nPatterns)\n",
    "\n",
    "m.Params.OutputFlag = 0\n",
    "\n",
    "for i in range(nDemands):\n",
    "    m.addConstr( sum( patterns[j][i] * x[j] for j in range(nPatterns) ) >= d[i])\n",
    "m.setObjective( sum(x[j] for j in range(nPatterns)), GRB.MINIMIZE)\n",
    "\n",
    "m.update()\n",
    "m.optimize()\n",
    "\n",
    "x_vals = [ x[j].x for j in range(nPatterns)]\n",
    "nonzero_pattern_indices = [j for j in range(nPatterns) if x_vals[j] > 0]\n",
    "print(\"Objective value: \", m.objval)\n",
    "for j in nonzero_pattern_indices:\n",
    "    print(\"Pattern \", j, \": \", patterns[j], \" -- cut \", x_vals[j], \" rolls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these patterns look very different from the ones in our exact solution. (In the exact solution, the patterns are much sparser.) \n",
    "\n",
    "This provides us some insight into why this randomization method works (unreasonably) well -- there are lots of nearly optimal solutions to the true problem that use different patterns. Although there may just be one singular optimal solution, by randomly sampling patterns, we are likely to sample some of the patterns that participate in the nearly optimal solutions, and thus be able to form a nearly optimal solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
